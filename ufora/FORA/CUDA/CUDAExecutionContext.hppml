/***************************************************************************
    Copyright 2015 Ufora Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
****************************************************************************/

#pragma once

#include <string>
#include <boost/thread.hpp>
#include "../Core/ImplValContainer.hppml"
#include "../../core/PolymorphicSharedPtr.hpp"


//forward declaration for an opaque type that CUDAExecutionContext uses
//internally to manage CUDA state, so that CUDA internals
//don't pollute the rest of the codebase
class CUDAExecutionContextInternalState;
class NativeCFG;
class Runtime;
class Type;

class CUDAExecutionContext :
		public PolymorphicSharedPtrBase<CUDAExecutionContext> {
private:
	//returns whether this binary was built with CUDA support
	//if not, then creating an object of this type will throw
	//an exception
	static bool	isCUDASupportCompiledIn(void);

	//pushes a kernel into the execution context
	//throws an exception if nativeCFGIsValidPTXVectorApplyKernel
	//is false with argument inCFG
	void	define(			const std::string& inKernelName,
							const NativeCFG& inCFG,
							const Type& inInputType,
							const Type& inOutputType);

	//execute the kernel defined by inKernelName,
	//and return the new vector.
	//will throw an exception if halted or there
	//is any other problem
	ImplValContainer	executeKernel(
							const std::string&	inKernelName,
							ImplValContainer	inApplyObject,
							ImplValContainer	inSourceVector
							);

public:
	CUDAExecutionContext();

	ImplValContainer	executeKernel(
							ImplValContainer	inApplyObject,
							ImplValContainer	inSourceVector
							);
private:
	map<std::string, NativeCFG> mNativeKernelsByName;

	map<std::string, std::string> mPTXKernelsByName;

	map<std::string, std::string> mPTXKernelFunctionNames;

	map<std::string, pair<Type, Type> > mInputOutputTypesByName;

	CUDAExecutionContextInternalState* mCUDAState;

	boost::recursive_mutex mMutex;
};
